{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Reacher_Windows_x86_64/Reacher.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import statistics\n",
    "import torch.distributions as tdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy_Net, self).__init__()\n",
    "        self.l1 = nn.Linear(33,64)\n",
    "        self.l2 = nn.Linear(64,64)\n",
    "        self.l3 = nn.Linear(64,4)\n",
    "\n",
    "    def forward(self, state):\n",
    "        state = F.tanh(self.l1(state))\n",
    "        state = F.tanh(self.l2(state))\n",
    "        state = F.tanh(self.l3(state))\n",
    "        return state\n",
    "    \n",
    "class Critic_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic_Net, self).__init__()\n",
    "        self.l1 = nn.Linear(33,64)\n",
    "        self.l2 = nn.Linear(64,64)\n",
    "        self.l3 = nn.Linear(64,1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        state = F.tanh(self.l1(state))\n",
    "        state = F.tanh(self.l2(state))\n",
    "        state = F.tanh(self.l3(state))\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor():\n",
    "    def __init__(self,action_size, discount_rate, p_net, c_net):\n",
    "        self.pi = p_net\n",
    "        self.value_est = c_net\n",
    "        self.optimizer = optim.Adam(self.pi.parameters(), lr=0.001)\n",
    "        self.optimizer2 = optim.RMSprop(self.value_est.parameters(), lr=0.001)\n",
    "        self.scheduler = optim.lr_scheduler.ExponentialLR(self.optimizer, 0.995)\n",
    "        self.scheduler2 = optim.lr_scheduler.ExponentialLR(self.optimizer2, 0.99)\n",
    "        self.discount = discount_rate\n",
    "        #Used to create covariance matrix to get actions and calculate action probability\n",
    "        #Covariance is always 0, Variance annealed to 0.5\n",
    "        self.var = torch.tensor([2.0])\n",
    "    def get_action(self,state):\n",
    "        prob = self.pi(torch.from_numpy(state).float())\n",
    "        prob = tdist.multivariate_normal.MultivariateNormal(prob[:,:action_space], torch.eye(4) * self.var)\n",
    "        return torch.clamp(prob.sample(),-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 350\n",
    "action_space = 4\n",
    "epsilon = 0.2\n",
    "pi = Policy_Net()\n",
    "critic = Critic_Net()\n",
    "Agent = Actor(33, 0.99, pi,critic)\n",
    "traj_list = list()\n",
    "traj_rewards = list()\n",
    "batch_size = 150\n",
    "batches = 100\n",
    "av_rew = 0\n",
    "discount = 0.96#Low discount rate resulted in better performance, likely due to nature of environment\n",
    "rew_list = list()\n",
    "advantage_rewards = list()\n",
    "advantage_list = list()\n",
    "score_list = list()\n",
    "traj_num = 1#How often to update policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last action prob :tensor(-5.5611)\n",
      "1 game average :0.225999994948506\n",
      "total game average :0.225999994948506\n",
      "last action prob :tensor(-5.6808)\n",
      "1 game average :0.32999999262392526\n",
      "total game average :0.27799999378621565\n",
      "last action prob :tensor(-5.1842)\n",
      "1 game average :0.5129999885335577\n",
      "total game average :0.35633332536866297\n",
      "last action prob :tensor(-6.7789)\n",
      "1 game average :0.6684999850578628\n",
      "total game average :0.43437499029096294\n",
      "last action prob :tensor(-6.4992)\n",
      "1 game average :0.6804999847896417\n",
      "total game average :0.4835999891906987\n",
      "last action prob :tensor(-6.1649)\n",
      "1 game average :0.5449999878183018\n",
      "total game average :0.49383332229529914\n",
      "last action prob :tensor(-5.0554)\n",
      "1 game average :0.6159999862313293\n",
      "total game average :0.5112857028575892\n",
      "last action prob :tensor(-6.0813)\n",
      "1 game average :0.8664999806322196\n",
      "total game average :0.555687487579418\n",
      "last action prob :tensor(-5.3172)\n",
      "1 game average :1.2404999722726633\n",
      "total game average :0.6317777636564452\n",
      "last action prob :tensor(-6.0871)\n",
      "1 game average :1.1504999742843207\n",
      "total game average :0.6836499847192328\n",
      "last action prob :tensor(-5.5501)\n",
      "1 game average :1.3809999691322412\n",
      "total game average :0.7470454378476881\n",
      "last action prob :tensor(-5.0007)\n",
      "1 game average :0.91499997954816\n",
      "total game average :0.7610416496560607\n",
      "last action prob :tensor(-4.9954)\n",
      "1 game average :1.3699999693781097\n",
      "total game average :0.8078845973269876\n",
      "last action prob :tensor(-5.7632)\n",
      "1 game average :1.3414999700151393\n",
      "total game average :0.845999981090427\n",
      "last action prob :tensor(-5.7032)\n",
      "1 game average :1.5669999649748176\n",
      "total game average :0.8940666466827197\n",
      "last action prob :tensor(-5.6279)\n",
      "1 game average :1.584499964583658\n",
      "total game average :0.9372187290515284\n",
      "last action prob :tensor(-4.9730)\n",
      "1 game average :1.4999999664723858\n",
      "total game average :0.9703235077233436\n",
      "last action prob :tensor(-6.6822)\n",
      "1 game average :1.2169999727979293\n",
      "total game average :0.9840277557830428\n",
      "last action prob :tensor(-4.8823)\n",
      "1 game average :1.4329999679699523\n",
      "total game average :1.0076578722139327\n",
      "last action prob :tensor(-5.1277)\n",
      "1 game average :0.9599999785423315\n",
      "total game average :1.0052749775303527\n",
      "last action prob :tensor(-5.0660)\n",
      "1 game average :1.3564999696798612\n",
      "total game average :1.0219999771565198\n",
      "last action prob :tensor(-5.3314)\n",
      "1 game average :1.4019999686628575\n",
      "total game average :1.0392727040431715\n",
      "last action prob :tensor(-5.0492)\n",
      "1 game average :1.3319999702274776\n",
      "total game average :1.0519999764859675\n",
      "last action prob :tensor(-6.1950)\n",
      "1 game average :1.9069999573752134\n",
      "total game average :1.087624975689686\n",
      "last action prob :tensor(-6.0657)\n",
      "1 game average :1.8334999590180738\n",
      "total game average :1.1174599750228216\n",
      "last action prob :tensor(-6.6308)\n",
      "1 game average :1.3014999709092046\n",
      "total game average :1.124538436403067\n",
      "last action prob :tensor(-4.8014)\n",
      "1 game average :1.7314999612979545\n",
      "total game average :1.1470184928806555\n",
      "last action prob :tensor(-5.2627)\n",
      "1 game average :1.4144999683834585\n",
      "total game average :1.1565714027200413\n",
      "last action prob :tensor(-4.8376)\n",
      "1 game average :1.5164999661035816\n",
      "total game average :1.1689827324918876\n",
      "last action prob :tensor(-5.0783)\n",
      "1 game average :1.710499961767338\n",
      "total game average :1.1870333068010692\n",
      "last action prob :tensor(-5.0811)\n",
      "1 game average :1.7934999599121495\n",
      "total game average :1.2065967472240071\n",
      "last action prob :tensor(-4.9631)\n",
      "1 game average :1.6519999630749165\n",
      "total game average :1.220515597719348\n",
      "last action prob :tensor(-4.9387)\n",
      "1 game average :1.4909999666735456\n",
      "total game average :1.2287120937482632\n",
      "last action prob :tensor(-6.2654)\n",
      "1 game average :1.6089999640360404\n",
      "total game average :1.2398970311096684\n",
      "last action prob :tensor(-4.8909)\n",
      "1 game average :1.6314999635331258\n",
      "total game average :1.251085686321767\n",
      "last action prob :tensor(-6.0916)\n",
      "1 game average :1.4504999675787935\n",
      "total game average :1.25662497191224\n",
      "last action prob :tensor(-5.4753)\n",
      "1 game average :1.9909999554976745\n",
      "total game average :1.276472944441576\n",
      "last action prob :tensor(-4.8310)\n",
      "1 game average :1.847499958705154\n",
      "total game average :1.291499971132723\n",
      "last action prob :tensor(-4.8127)\n",
      "1 game average :1.8139999594539296\n",
      "total game average :1.3048974067307026\n",
      "last action prob :tensor(-5.5513)\n",
      "1 game average :2.3694999470375273\n",
      "total game average :1.3315124702383732\n",
      "last action prob :tensor(-6.2537)\n",
      "1 game average :1.6769999625161245\n",
      "total game average :1.3399389944402698\n",
      "last action prob :tensor(-4.9323)\n",
      "1 game average :1.775999960303294\n",
      "total game average :1.3503213983893894\n",
      "last action prob :tensor(-5.3408)\n",
      "1 game average :2.1299999523907815\n",
      "total game average :1.3684534577847707\n",
      "last action prob :tensor(-5.3992)\n",
      "1 game average :1.7564999607391576\n",
      "total game average :1.3772726964882793\n",
      "last action prob :tensor(-4.7016)\n",
      "1 game average :1.6004999642260351\n",
      "total game average :1.3822333024380071\n",
      "last action prob :tensor(-6.8338)\n",
      "1 game average :1.9969999553635627\n",
      "total game average :1.3955977948929106\n",
      "last action prob :tensor(-4.6010)\n",
      "1 game average :2.230999950133249\n",
      "total game average :1.4133723088341945\n",
      "last action prob :tensor(-6.1318)\n",
      "1 game average :2.323999948054544\n",
      "total game average :1.4323437179846186\n",
      "last action prob :tensor(-5.7107)\n",
      "1 game average :2.2679999493062413\n",
      "total game average :1.4493979267871007\n",
      "last action prob :tensor(-5.1304)\n",
      "1 game average :2.1014999530278056\n",
      "total game average :1.4624399673119148\n",
      "last action prob :tensor(-5.7301)\n",
      "1 game average :2.0754999536089476\n",
      "total game average :1.4744607513569548\n",
      "last action prob :tensor(-5.4221)\n",
      "1 game average :2.0729999536648314\n",
      "total game average :1.4859711206321065\n",
      "last action prob :tensor(-4.5937)\n",
      "1 game average :2.081999953463672\n",
      "total game average :1.4972169476666644\n",
      "last action prob :tensor(-5.8456)\n",
      "1 game average :3.1424999297596337\n",
      "total game average :1.5276851510387564\n",
      "last action prob :tensor(-4.7426)\n",
      "1 game average :1.9414999566040823\n",
      "total game average :1.5352090565944896\n",
      "last action prob :tensor(-4.8777)\n",
      "1 game average :2.6839999400079093\n",
      "total game average :1.5557231795125863\n",
      "last action prob :tensor(-5.7788)\n",
      "1 game average :2.1499999519437423\n",
      "total game average :1.5661490878008522\n",
      "last action prob :tensor(-5.3749)\n",
      "1 game average :2.6739999402314343\n",
      "total game average :1.5852499645668967\n",
      "last action prob :tensor(-5.3246)\n",
      "1 game average :2.212499950546759\n",
      "total game average :1.5958813202614708\n",
      "last action prob :tensor(-5.4208)\n",
      "1 game average :2.1724999514408236\n",
      "total game average :1.6054916307811267\n",
      "last action prob :tensor(-5.4460)\n",
      "1 game average :2.462499944958822\n",
      "total game average :1.6195409474069904\n",
      "last action prob :tensor(-4.7597)\n",
      "1 game average :3.2239999279379683\n",
      "total game average :1.645419318060716\n",
      "last action prob :tensor(-6.7150)\n",
      "1 game average :2.671499940287299\n",
      "total game average :1.6617063120643125\n",
      "last action prob :tensor(-5.8595)\n",
      "1 game average :2.814499937091008\n",
      "total game average :1.6797187124553548\n",
      "last action prob :tensor(-4.4768)\n",
      "1 game average :3.1029999306425347\n",
      "total game average :1.7016153465813115\n",
      "last action prob :tensor(-5.0189)\n",
      "1 game average :2.825499936845138\n",
      "total game average :1.7186439009792482\n",
      "last action prob :tensor(-6.3054)\n",
      "1 game average :2.3374999477527942\n",
      "total game average :1.7278805583937786\n",
      "last action prob :tensor(-4.8554)\n",
      "1 game average :2.8214999369345546\n",
      "total game average :1.743963196313496\n",
      "last action prob :tensor(-4.8422)\n",
      "1 game average :3.285499926563342\n",
      "total game average :1.7663043083461025\n",
      "last action prob :tensor(-4.3805)\n",
      "1 game average :3.2239999279379545\n",
      "total game average :1.787128531483129\n",
      "last action prob :tensor(-5.0640)\n",
      "1 game average :3.1919999286532263\n",
      "total game average :1.8069154525700317\n",
      "last action prob :tensor(-4.8015)\n",
      "1 game average :3.594499919656651\n",
      "total game average :1.8317430146129015\n",
      "last action prob :tensor(-5.6042)\n",
      "1 game average :3.774999915622168\n",
      "total game average :1.8583629721609736\n",
      "last action prob :tensor(-4.3720)\n",
      "1 game average :3.477999922260624\n",
      "total game average :1.880249957973131\n",
      "last action prob :tensor(-5.4770)\n",
      "1 game average :4.4434999006800195\n",
      "total game average :1.9144266238758898\n",
      "last action prob :tensor(-5.5729)\n",
      "1 game average :5.416999878920617\n",
      "total game average :1.9605131140738468\n",
      "last action prob :tensor(-4.9355)\n",
      "1 game average :4.83249989198521\n",
      "total game average :1.9978116436571112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last action prob :tensor(-5.8055)\n",
      "1 game average :4.609499896969644\n",
      "total game average :2.0312948263918873\n",
      "last action prob :tensor(-5.2899)\n",
      "1 game average :5.2574998824857095\n",
      "total game average :2.0721328650766195\n",
      "last action prob :tensor(-5.7714)\n",
      "1 game average :4.558499898109576\n",
      "total game average :2.1032124529895313\n",
      "last action prob :tensor(-4.8380)\n",
      "1 game average :5.741499871667481\n",
      "total game average :2.148129581615185\n",
      "last action prob :tensor(-4.2552)\n",
      "1 game average :5.413999878987682\n",
      "total game average :2.187957268168508\n",
      "last action prob :tensor(-4.5286)\n",
      "1 game average :5.4289998786524\n",
      "total game average :2.227005974318917\n",
      "last action prob :tensor(-4.2300)\n",
      "1 game average :4.557999898120745\n",
      "total game average :2.2547559019832244\n",
      "last action prob :tensor(-6.5335)\n",
      "1 game average :5.60999987460672\n",
      "total game average :2.2942293604846773\n",
      "last action prob :tensor(-5.0027)\n",
      "1 game average :6.6639998510479845\n",
      "total game average :2.345040645258669\n",
      "last action prob :tensor(-4.9998)\n",
      "1 game average :5.990499866101889\n",
      "total game average :2.3869424753833037\n",
      "last action prob :tensor(-6.6253)\n",
      "1 game average :6.421999856457109\n",
      "total game average :2.4327954001682333\n",
      "last action prob :tensor(-5.0700)\n",
      "1 game average :6.566499853227298\n",
      "total game average :2.4792415176183353\n",
      "last action prob :tensor(-4.6145)\n",
      "1 game average :7.995499821286639\n",
      "total game average :2.540533276547983\n",
      "last action prob :tensor(-5.5629)\n",
      "1 game average :8.078499819431434\n",
      "total game average :2.6013900517445046\n",
      "last action prob :tensor(-4.2760)\n",
      "1 game average :8.133499818202113\n",
      "total game average :2.6615216796407832\n",
      "last action prob :tensor(-4.7248)\n",
      "1 game average :7.440999833680692\n",
      "total game average :2.712913917856266\n",
      "last action prob :tensor(-5.3333)\n",
      "1 game average :8.113499818649137\n",
      "total game average :2.7703669593540625\n",
      "last action prob :tensor(-4.7409)\n",
      "1 game average :8.907499800901881\n",
      "total game average :2.8349683576861446\n",
      "last action prob :tensor(-6.1333)\n",
      "1 game average :7.465499833133063\n",
      "total game average :2.883203060555383\n",
      "last action prob :tensor(-4.4427)\n",
      "1 game average :8.683999805897484\n",
      "total game average :2.9430050888578787\n",
      "last action prob :tensor(-5.0104)\n",
      "1 game average :8.929499800410134\n",
      "total game average :3.0040917695880043\n",
      "last action prob :tensor(-4.6299)\n",
      "1 game average :9.380499790329484\n",
      "total game average :3.068499931413676\n",
      "last action prob :tensor(-5.6257)\n",
      "1 game average :10.665999761596316\n",
      "total game average :3.144474929715502\n",
      "last action prob :tensor(-4.9030)\n",
      "1 game average :8.88649980137127\n",
      "total game average :3.2013266611180344\n",
      "last action prob :tensor(-6.8538)\n",
      "1 game average :9.831499780248793\n",
      "total game average :3.2663283583644147\n",
      "last action prob :tensor(-5.8099)\n",
      "1 game average :10.0204997760244\n",
      "total game average :3.331902838147521\n",
      "last action prob :tensor(-4.0957)\n",
      "1 game average :10.731499760132252\n",
      "total game average :3.4030528085512204\n",
      "last action prob :tensor(-4.6406)\n",
      "1 game average :9.790999781154111\n",
      "total game average :3.4638903987664857\n",
      "last action prob :tensor(-5.4392)\n",
      "1 game average :11.810999736003568\n",
      "total game average :3.542636713268722\n",
      "last action prob :tensor(-4.1245)\n",
      "1 game average :11.276499747950593\n",
      "total game average :3.614915807050796\n",
      "last action prob :tensor(-4.2150)\n",
      "1 game average :11.04099975321443\n",
      "total game average :3.6836758435893477\n",
      "last action prob :tensor(-3.9848)\n",
      "1 game average :11.766999736987046\n",
      "total game average :3.7578347783911616\n",
      "last action prob :tensor(-4.0787)\n",
      "1 game average :11.402999745123106\n",
      "total game average :3.827336278088725\n",
      "last action prob :tensor(-4.4151)\n",
      "1 game average :11.708499738294664\n",
      "total game average :3.8983377507031927\n",
      "last action prob :tensor(-4.6342)\n",
      "1 game average :11.820499735791218\n",
      "total game average :3.969071339855764\n",
      "last action prob :tensor(-4.5416)\n",
      "1 game average :10.337499768938857\n",
      "total game average :4.025429113564464\n",
      "last action prob :tensor(-4.6440)\n",
      "1 game average :12.106999729387448\n",
      "total game average :4.096320083878701\n",
      "last action prob :tensor(-4.1983)\n",
      "1 game average :12.145499728526918\n",
      "total game average :4.166312950353903\n",
      "last action prob :tensor(-4.3069)\n",
      "1 game average :13.614999695681048\n",
      "total game average :4.24776714643431\n",
      "last action prob :tensor(-4.3983)\n",
      "1 game average :13.225999704375864\n",
      "total game average :4.324504176844066\n",
      "last action prob :tensor(-5.4755)\n",
      "1 game average :11.14049975099045\n",
      "total game average :4.382266851201239\n",
      "last action prob :tensor(-4.8611)\n",
      "1 game average :10.932999755628416\n",
      "total game average :4.437315026868695\n",
      "last action prob :tensor(-4.5663)\n",
      "1 game average :12.068499730248048\n",
      "total game average :4.500908232730189\n",
      "last action prob :tensor(-7.0726)\n",
      "1 game average :11.423999744653697\n",
      "total game average :4.558123865060136\n",
      "last action prob :tensor(-4.1047)\n",
      "1 game average :10.39349976768719\n",
      "total game average :4.6059548150816685\n",
      "last action prob :tensor(-3.9996)\n",
      "1 game average :12.085999729856821\n",
      "total game average :4.666768188372523\n",
      "last action prob :tensor(-3.8300)\n",
      "1 game average :13.698999693803538\n",
      "total game average :4.739608765029225\n",
      "last action prob :tensor(-3.8220)\n",
      "1 game average :12.17899972777809\n",
      "total game average :4.799123892731216\n",
      "last action prob :tensor(-4.9590)\n",
      "1 game average :12.619499717932188\n",
      "total game average :4.861190367534398\n",
      "last action prob :tensor(-6.3387)\n",
      "1 game average :12.275999725610008\n",
      "total game average :4.919574693188538\n",
      "last action prob :tensor(-3.8634)\n",
      "1 game average :12.011499731522052\n",
      "total game average :4.974980357550518\n",
      "last action prob :tensor(-3.7790)\n",
      "1 game average :12.474999721162057\n",
      "total game average :5.033120042539754\n",
      "last action prob :tensor(-4.2545)\n",
      "1 game average :12.936499710846665\n",
      "total game average :5.093915270757499\n",
      "last action prob :tensor(-4.4982)\n",
      "1 game average :13.789499691780644\n",
      "total game average :5.16029377778821\n",
      "last action prob :tensor(-4.7119)\n",
      "1 game average :11.229999748989904\n",
      "total game average :5.206276398782163\n",
      "last action prob :tensor(-4.0967)\n",
      "1 game average :11.943499733041964\n",
      "total game average :5.25693221332547\n",
      "last action prob :tensor(-6.3479)\n",
      "1 game average :11.50599974282088\n",
      "total game average :5.303567045635138\n",
      "last action prob :tensor(-4.7819)\n",
      "1 game average :12.475499721150873\n",
      "total game average :5.35669247286118\n",
      "last action prob :tensor(-4.9545)\n",
      "1 game average :13.321499702241255\n",
      "total game average :5.415257231900739\n",
      "last action prob :tensor(-3.7997)\n",
      "1 game average :12.04499973077329\n",
      "total game average :5.463649512914407\n",
      "last action prob :tensor(-3.7637)\n",
      "1 game average :12.814499713573616\n",
      "total game average :5.516916543353966\n",
      "last action prob :tensor(-4.5315)\n",
      "1 game average :14.833499668445468\n",
      "total game average :5.583942321232323\n",
      "last action prob :tensor(-4.5931)\n",
      "1 game average :15.852499645668983\n",
      "total game average :5.657289159264013\n",
      "last action prob :tensor(-3.7152)\n",
      "1 game average :12.005499731656176\n",
      "total game average :5.702311929280979\n",
      "last action prob :tensor(-5.1314)\n",
      "1 game average :16.112499639857553\n",
      "total game average :5.775623110341377\n",
      "last action prob :tensor(-5.0028)\n",
      "1 game average :16.473499631788567\n",
      "total game average :5.850433435666183\n",
      "last action prob :tensor(-3.7596)\n",
      "1 game average :12.682999716512859\n",
      "total game average :5.897881812616507\n",
      "last action prob :tensor(-4.8495)\n",
      "1 game average :14.286999680660637\n",
      "total game average :5.955737797913363\n",
      "last action prob :tensor(-4.0659)\n",
      "1 game average :14.719499670993573\n",
      "total game average :6.0157635641673375\n",
      "last action prob :tensor(-4.6425)\n",
      "1 game average :15.162499661091735\n",
      "total game average :6.077986258704238\n",
      "last action prob :tensor(-3.8467)\n",
      "1 game average :14.98599966503683\n",
      "total game average :6.138175538476756\n",
      "last action prob :tensor(-4.3156)\n",
      "1 game average :13.818499691132414\n",
      "total game average :6.189721338159008\n",
      "last action prob :tensor(-5.3068)\n",
      "1 game average :14.646999672614033\n",
      "total game average :6.246103193722042\n",
      "last action prob :tensor(-5.3544)\n",
      "1 game average :14.154999683611088\n",
      "total game average :6.2984799916683265\n",
      "last action prob :tensor(-4.7554)\n",
      "1 game average :14.621999673172818\n",
      "total game average :6.353239989572962\n",
      "last action prob :tensor(-4.9103)\n",
      "1 game average :16.560499629844\n",
      "total game average :6.41995410486885\n",
      "last action prob :tensor(-4.1914)\n",
      "1 game average :13.481999698653826\n",
      "total game average :6.465811543789532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last action prob :tensor(-3.9189)\n",
      "1 game average :16.052499641198672\n",
      "total game average :6.527661144417978\n",
      "last action prob :tensor(-5.0362)\n",
      "1 game average :18.10149959539992\n",
      "total game average :6.601852416539657\n",
      "last action prob :tensor(-4.6826)\n",
      "1 game average :15.390999655984357\n",
      "total game average :6.65783424609026\n",
      "last action prob :tensor(-3.7859)\n",
      "1 game average :14.859499667864306\n",
      "total game average :6.709743520911616\n",
      "last action prob :tensor(-4.2227)\n",
      "1 game average :16.07599964067336\n",
      "total game average :6.7686507921050865\n",
      "last action prob :tensor(-4.8594)\n",
      "1 game average :15.142999661527561\n",
      "total game average :6.820990472538976\n",
      "last action prob :tensor(-3.9075)\n",
      "1 game average :16.95949962092563\n",
      "total game average :6.883962579050695\n",
      "last action prob :tensor(-3.9568)\n",
      "1 game average :17.10099961776284\n",
      "total game average :6.947030708919289\n",
      "last action prob :tensor(-4.0624)\n",
      "1 game average :16.954999621026182\n",
      "total game average :7.0084292912021535\n",
      "last action prob :tensor(-3.7452)\n",
      "1 game average :17.400999611057365\n",
      "total game average :7.071798622420783\n",
      "last action prob :tensor(-3.9639)\n",
      "1 game average :17.218499615136533\n",
      "total game average :7.133293779952394\n",
      "last action prob :tensor(-3.6849)\n",
      "1 game average :16.902499622199684\n",
      "total game average :7.192144417556293\n",
      "last action prob :tensor(-3.5715)\n",
      "1 game average :18.798499579820763\n",
      "total game average :7.2616435502644645\n",
      "last action prob :tensor(-3.8342)\n",
      "1 game average :16.50399963110684\n",
      "total game average :7.316657574555192\n",
      "last action prob :tensor(-4.9534)\n",
      "1 game average :16.51699963081626\n",
      "total game average :7.371097468379223\n",
      "last action prob :tensor(-3.5097)\n",
      "1 game average :17.65349960541354\n",
      "total game average :7.431582186832366\n",
      "last action prob :tensor(-3.5507)\n",
      "1 game average :16.993999620154508\n",
      "total game average :7.487502756617876\n",
      "last action prob :tensor(-3.7951)\n",
      "1 game average :16.76099962536246\n",
      "total game average :7.541418436087321\n",
      "last action prob :tensor(-3.7548)\n",
      "1 game average :18.09949959544461\n",
      "total game average :7.602447806950657\n",
      "last action prob :tensor(-4.9795)\n",
      "1 game average :19.137999572232392\n",
      "total game average :7.668744081463772\n",
      "last action prob :tensor(-4.3450)\n",
      "1 game average :20.626499538961795\n",
      "total game average :7.74278839836376\n",
      "last action prob :tensor(-5.6538)\n",
      "1 game average :19.031499574612848\n",
      "total game average :7.806928802774266\n",
      "last action prob :tensor(-3.5393)\n",
      "1 game average :19.12799957245592\n",
      "total game average :7.8708896545803775\n",
      "last action prob :tensor(-3.8671)\n",
      "1 game average :19.076499573607045\n",
      "total game average :7.93384251929401\n",
      "last action prob :tensor(-4.8480)\n",
      "1 game average :21.135499527584695\n",
      "total game average :8.007594793083344\n",
      "last action prob :tensor(-4.2601)\n",
      "1 game average :18.59349958440283\n",
      "total game average :8.066405375257341\n",
      "last action prob :tensor(-4.5912)\n",
      "1 game average :18.66099958289415\n",
      "total game average :8.124939044912793\n",
      "last action prob :tensor(-3.6861)\n",
      "1 game average :20.650499538425354\n",
      "total game average :8.193760805866159\n",
      "last action prob :tensor(-3.2386)\n",
      "1 game average :18.454999587498584\n",
      "total game average :8.249833148935188\n",
      "last action prob :tensor(-4.0293)\n",
      "1 game average :19.372999566979743\n",
      "total game average :8.310285140337605\n",
      "last action prob :tensor(-4.7971)\n",
      "1 game average :17.73749960353593\n",
      "total game average :8.361243056354894\n",
      "last action prob :tensor(-4.1589)\n",
      "1 game average :19.24599956981839\n",
      "total game average :8.419763252663836\n",
      "last action prob :tensor(-3.5031)\n",
      "1 game average :20.37199954465033\n",
      "total game average :8.483678954760022\n",
      "last action prob :tensor(-3.2402)\n",
      "1 game average :18.690999582223597\n",
      "total game average :8.537973213416743\n",
      "last action prob :tensor(-3.8187)\n",
      "1 game average :20.369499544706223\n",
      "total game average :8.600573881836265\n",
      "last action prob :tensor(-3.1756)\n",
      "1 game average :19.675499560218345\n",
      "total game average :8.658862964354066\n",
      "last action prob :tensor(-4.1291)\n",
      "1 game average :19.03699957448991\n",
      "total game average :8.713198758124411\n",
      "last action prob :tensor(-5.0541)\n",
      "1 game average :23.043999484926427\n",
      "total game average :8.787838345243172\n",
      "last action prob :tensor(-4.8816)\n",
      "1 game average :21.74199951402842\n",
      "total game average :8.854958351299054\n",
      "last action prob :tensor(-3.2482)\n",
      "1 game average :20.93049953216683\n",
      "total game average :8.917203408932393\n",
      "last action prob :tensor(-6.2486)\n",
      "1 game average :20.559499540459335\n",
      "total game average :8.97690749165817\n",
      "last action prob :tensor(-3.7401)\n",
      "1 game average :21.696499515045474\n",
      "total game average :9.041803369328514\n",
      "last action prob :tensor(-3.8381)\n",
      "1 game average :23.669499470945514\n",
      "total game average :9.116055633803727\n",
      "last action prob :tensor(-5.7687)\n",
      "1 game average :21.91099951025096\n",
      "total game average :9.180676562472653\n",
      "last action prob :tensor(-4.0882)\n",
      "1 game average :22.342499500606174\n",
      "total game average :9.246816376232118\n",
      "last action prob :tensor(-3.8745)\n",
      "1 game average :22.472999497689322\n",
      "total game average :9.312947291839404\n",
      "last action prob :tensor(-3.2799)\n",
      "1 game average :21.851499511580908\n",
      "total game average :9.375328148654038\n",
      "last action prob :tensor(-3.3866)\n",
      "1 game average :23.976999464072293\n",
      "total game average :9.447613650215516\n",
      "last action prob :tensor(-4.2012)\n",
      "1 game average :23.279999479651437\n",
      "total game average :9.515753481887613\n",
      "last action prob :tensor(-4.8886)\n",
      "1 game average :23.489499474968806\n",
      "total game average :9.584252236755658\n",
      "last action prob :tensor(-3.2977)\n",
      "1 game average :21.99099950846288\n",
      "total game average :9.644772955154231\n",
      "last action prob :tensor(-3.6837)\n",
      "1 game average :24.0379994627089\n",
      "total game average :9.714642986744302\n",
      "last action prob :tensor(-4.0308)\n",
      "1 game average :25.179999437183273\n",
      "total game average :9.789354853654636\n",
      "last action prob :tensor(-6.2674)\n",
      "1 game average :23.753499469067883\n",
      "total game average :9.856490164305661\n",
      "last action prob :tensor(-4.6817)\n",
      "1 game average :21.39649952175098\n",
      "total game average :9.911705520082911\n",
      "last action prob :tensor(-3.0466)\n",
      "1 game average :22.077999506518275\n",
      "total game average :9.96964025335165\n",
      "last action prob :tensor(-3.1480)\n",
      "1 game average :22.7129994923249\n",
      "total game average :10.030035320834937\n",
      "last action prob :tensor(-2.9538)\n",
      "1 game average :24.35649945558981\n",
      "total game average :10.097612981847933\n",
      "last action prob :tensor(-3.1822)\n",
      "1 game average :24.186999459378413\n",
      "total game average :10.163760336202536\n",
      "last action prob :tensor(-3.4250)\n",
      "1 game average :23.741499469336176\n",
      "total game average :10.227207715329328\n",
      "last action prob :tensor(-4.6090)\n",
      "1 game average :24.15999945998195\n",
      "total game average :10.292011397862597\n",
      "last action prob :tensor(-3.5005)\n",
      "1 game average :24.32249945634981\n",
      "total game average :10.356967361096334\n",
      "last action prob :tensor(-4.2646)\n",
      "1 game average :23.952999464608773\n",
      "total game average :10.419621886918971\n",
      "last action prob :tensor(-3.8844)\n",
      "1 game average :21.53549951864411\n",
      "total game average :10.470612151284682\n",
      "last action prob :tensor(-3.2888)\n",
      "1 game average :24.91699944306168\n",
      "total game average :10.53657739005992\n",
      "last action prob :tensor(-3.9241)\n",
      "1 game average :25.517499429639383\n",
      "total game average :10.604672490239826\n",
      "last action prob :tensor(-5.1108)\n",
      "1 game average :24.107999461144257\n",
      "total game average :10.665773517257493\n",
      "last action prob :tensor(-3.0869)\n",
      "1 game average :24.827499445062195\n",
      "total game average :10.729565075490846\n",
      "last action prob :tensor(-3.2647)\n",
      "1 game average :24.512499452102983\n",
      "total game average :10.791371956103458\n",
      "last action prob :tensor(-3.4767)\n",
      "1 game average :24.160499459970804\n",
      "total game average :10.851055561031435\n",
      "last action prob :tensor(-3.4880)\n",
      "1 game average :24.005499463435246\n",
      "total game average :10.90951975615323\n",
      "last action prob :tensor(-4.0019)\n",
      "1 game average :26.75249940203502\n",
      "total game average :10.979621436002265\n",
      "last action prob :tensor(-4.5663)\n",
      "1 game average :26.59099940564479\n",
      "total game average :11.0483940261769\n",
      "last action prob :tensor(-3.0164)\n",
      "1 game average :27.740999379940277\n",
      "total game average :11.121607207553055\n",
      "last action prob :tensor(-2.9374)\n",
      "1 game average :25.5629994286224\n",
      "total game average :11.184670055679996\n",
      "last action prob :tensor(-3.0728)\n",
      "1 game average :26.65399940423668\n",
      "total game average :11.251928009369374\n",
      "last action prob :tensor(-3.4910)\n",
      "1 game average :25.595499427896044\n",
      "total game average :11.314021392133558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last action prob :tensor(-4.5502)\n",
      "1 game average :27.022499396000086\n",
      "total game average :11.381730349046775\n",
      "last action prob :tensor(-3.4205)\n",
      "1 game average :28.787499356549272\n",
      "total game average :11.456433220323609\n",
      "last action prob :tensor(-3.1814)\n",
      "1 game average :28.69699935857204\n",
      "total game average :11.530110853393047\n",
      "last action prob :tensor(-3.0286)\n",
      "1 game average :28.328499366808657\n",
      "total game average :11.601593357705454\n",
      "last action prob :tensor(-2.9152)\n",
      "1 game average :27.261999390646892\n",
      "total game average :11.667951010387409\n",
      "last action prob :tensor(-3.2571)\n",
      "1 game average :29.55449933940546\n",
      "total game average :11.743421678442338\n",
      "last action prob :tensor(-3.7143)\n",
      "1 game average :28.401999365165818\n",
      "total game average :11.813415702336135\n",
      "last action prob :tensor(-3.5414)\n",
      "1 game average :30.67499931436039\n",
      "total game average :11.89233446221908\n",
      "last action prob :tensor(-4.7985)\n",
      "1 game average :29.379999343305805\n",
      "total game average :11.965199732556943\n",
      "last action prob :tensor(-6.2464)\n",
      "1 game average :30.704499313700953\n",
      "total game average :12.042956162354221\n",
      "last action prob :tensor(-5.8425)\n",
      "1 game average :30.564999316818962\n",
      "total game average :12.1194935307611\n",
      "last action prob :tensor(-5.0249)\n",
      "1 game average :30.36899932119988\n",
      "total game average :12.194594377635333\n",
      "last action prob :tensor(-6.2326)\n",
      "1 game average :29.15449934834609\n",
      "total game average :12.264102184892344\n",
      "last action prob :tensor(-3.5135)\n",
      "1 game average :31.148999303765567\n",
      "total game average :12.34118339762244\n",
      "last action prob :tensor(-3.6742)\n",
      "1 game average :30.257499323692144\n",
      "total game average :12.414013950167439\n",
      "last action prob :tensor(-2.6487)\n",
      "1 game average :31.64249929273494\n",
      "total game average :12.49186206896326\n",
      "last action prob :tensor(-4.1300)\n",
      "1 game average :27.616999382712024\n",
      "total game average :12.552850525873536\n",
      "last action prob :tensor(-5.4417)\n",
      "1 game average :34.85649922089654\n",
      "total game average :12.642423412198932\n",
      "last action prob :tensor(-3.9287)\n",
      "1 game average :32.033999283984215\n",
      "total game average :12.719989715686072\n",
      "last action prob :tensor(-2.7541)\n",
      "1 game average :30.46399931907649\n",
      "total game average :12.790682981038223\n",
      "last action prob :tensor(-2.7530)\n",
      "1 game average :30.953499308135445\n",
      "total game average :12.862757649002896\n",
      "last action prob :tensor(-3.3620)\n",
      "1 game average :28.704499358404387\n",
      "total game average :12.925373228881954\n",
      "last action prob :tensor(-3.0862)\n",
      "1 game average :32.4824992739594\n",
      "total game average :13.002369788114542\n",
      "last action prob :tensor(-2.9026)\n",
      "1 game average :33.18249925831329\n",
      "total game average :13.081507550742772\n",
      "last action prob :tensor(-4.0910)\n",
      "1 game average :33.40299925338473\n",
      "total game average :13.160888377706218\n",
      "last action prob :tensor(-2.7901)\n",
      "1 game average :31.714499291125595\n",
      "total game average :13.233081416279836\n",
      "last action prob :tensor(-3.5172)\n",
      "1 game average :32.02549928417427\n",
      "total game average :13.305920245225161\n",
      "last action prob :tensor(-3.3367)\n",
      "1 game average :31.716999291069904\n",
      "total game average :13.377005492506417\n",
      "last action prob :tensor(-2.9025)\n",
      "1 game average :33.04899926129723\n",
      "total game average :13.452667007001764\n",
      "last action prob :tensor(-3.7859)\n",
      "1 game average :28.909999353811205\n",
      "total game average :13.511890502583409\n",
      "last action prob :tensor(-2.4963)\n",
      "1 game average :35.26099921185527\n",
      "total game average :13.594902367885974\n",
      "last action prob :tensor(-2.9649)\n",
      "1 game average :32.61149927107622\n",
      "total game average :13.667208819989359\n",
      "last action prob :tensor(-2.8803)\n",
      "1 game average :31.329499299731122\n",
      "total game average :13.734111435442927\n",
      "last action prob :tensor(-4.0642)\n",
      "1 game average :32.06949928319086\n",
      "total game average :13.803301578264616\n",
      "last action prob :tensor(-4.0003)\n",
      "1 game average :32.97099926304071\n",
      "total game average :13.875360592117158\n",
      "last action prob :tensor(-3.1772)\n",
      "1 game average :34.61999922618291\n",
      "total game average :13.953055867900174\n",
      "last action prob :tensor(-2.7679)\n",
      "1 game average :35.98699919562792\n",
      "total game average :14.03527207434692\n",
      "last action prob :tensor(-2.6781)\n",
      "1 game average :33.56949924966328\n",
      "total game average :14.107890019236573\n",
      "last action prob :tensor(-2.5005)\n",
      "1 game average :35.552999205328625\n",
      "total game average :14.18731634955543\n",
      "last action prob :tensor(-3.7600)\n",
      "1 game average :36.87749917572387\n",
      "total game average :14.271043961460112\n",
      "last action prob :tensor(-2.7747)\n",
      "1 game average :37.21699916813541\n",
      "total game average :14.355404090896418\n",
      "last action prob :tensor(-4.0414)\n",
      "1 game average :35.173999213799966\n",
      "total game average :14.431662681090204\n",
      "last action prob :tensor(-2.7044)\n",
      "1 game average :36.237499190028906\n",
      "total game average :14.511246026013337\n",
      "last action prob :tensor(-2.8354)\n",
      "1 game average :35.02399921715279\n",
      "total game average :14.5858378557993\n",
      "last action prob :tensor(-3.1484)\n",
      "1 game average :38.3334991431796\n",
      "total game average :14.671880106840533\n",
      "last action prob :tensor(-7.9994)\n",
      "1 game average :36.02049919487913\n",
      "total game average :14.748950933873163\n",
      "last action prob :tensor(-4.0197)\n",
      "1 game average :37.719499156903765\n",
      "total game average :14.831578805179028\n",
      "last action prob :tensor(-4.0072)\n",
      "1 game average :35.62099920380878\n",
      "total game average :14.906092856787017\n",
      "last action prob :tensor(-4.1774)\n",
      "1 game average :38.08649914870055\n",
      "total game average :14.98888002211528\n",
      "last action prob :tensor(-5.2777)\n",
      "1 game average :36.261499189492504\n",
      "total game average :15.064583293173563\n",
      "last action prob :tensor(-3.4229)\n",
      "1 game average :37.47199916243581\n",
      "total game average :15.14404221469577\n",
      "last action prob :tensor(-3.8983)\n",
      "1 game average :36.64549918090959\n",
      "total game average :15.220019094435042\n",
      "last action prob :tensor(-5.2379)\n",
      "1 game average :36.34449918763726\n",
      "total game average :15.294401066594206\n",
      "last action prob :tensor(-4.3637)\n",
      "1 game average :37.54799916073704\n",
      "total game average :15.372483866924533\n",
      "last action prob :tensor(-4.1130)\n",
      "1 game average :35.90599919743856\n",
      "total game average :15.444279375073181\n",
      "last action prob :tensor(-3.0801)\n",
      "1 game average :37.3584991649727\n",
      "total game average :15.52063554158851\n",
      "last action prob :tensor(-4.0721)\n",
      "1 game average :37.645999158546516\n",
      "total game average :15.597459720814056\n",
      "last action prob :tensor(-2.6953)\n",
      "1 game average :37.15849916944302\n",
      "total game average :15.672065393646681\n",
      "last action prob :tensor(-2.4749)\n",
      "1 game average :37.91199915260087\n",
      "total game average :15.748754820401697\n",
      "last action prob :tensor(-4.5862)\n",
      "1 game average :37.10149917071696\n",
      "total game average :15.822131948753297\n",
      "last action prob :tensor(-4.2689)\n",
      "1 game average :37.89099915307026\n",
      "total game average :15.897710261096847\n",
      "last action prob :tensor(-5.2780)\n",
      "1 game average :38.32999914325791\n",
      "total game average :15.974270974005245\n",
      "last action prob :tensor(-3.1551)\n",
      "1 game average :38.176499146688855\n",
      "total game average :16.04978875690553\n",
      "last action prob :tensor(-3.2317)\n",
      "1 game average :37.916499152500286\n",
      "total game average :16.123913198924495\n",
      "last action prob :tensor(-2.5285)\n",
      "1 game average :37.43649916322923\n",
      "total game average :16.19591517853363\n",
      "last action prob :tensor(-2.4005)\n",
      "1 game average :37.15499916952124\n",
      "total game average :16.266484484900595\n",
      "last action prob :tensor(-2.9769)\n",
      "1 game average :38.505999139323954\n",
      "total game average :16.341113728707384\n",
      "last action prob :tensor(-2.9686)\n",
      "1 game average :38.32299914341432\n",
      "total game average :16.41463174012781\n",
      "last action prob :tensor(-2.4646)\n",
      "1 game average :38.302499143872566\n",
      "total game average :16.48759129814029\n",
      "last action prob :tensor(-3.1644)\n",
      "1 game average :38.54849913837397\n",
      "total game average :16.56088335076565\n",
      "last action prob :tensor(-2.7059)\n",
      "1 game average :37.3989991640674\n",
      "total game average :16.629883734253404\n",
      "last action prob :tensor(-3.2281)\n",
      "1 game average :37.96449915142741\n",
      "total game average :16.70029500625728\n",
      "last action prob :tensor(-3.6494)\n",
      "1 game average :37.98799915090219\n",
      "total game average :16.77032034883835\n",
      "last action prob :tensor(-3.1566)\n",
      "1 game average :37.83699915427732\n",
      "total game average :16.83939142688897\n",
      "last action prob :tensor(-3.1562)\n",
      "1 game average :38.141499147471194\n",
      "total game average :16.909006158001986\n",
      "last action prob :tensor(-3.2176)\n",
      "1 game average :38.69399913512181\n",
      "total game average :16.97996704717827\n",
      "last action prob :tensor(-4.4616)\n",
      "1 game average :38.20649914601828\n",
      "total game average :17.048884359187493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last action prob :tensor(-3.2372)\n",
      "1 game average :38.040499149728795\n",
      "total game average :17.116818387635846\n",
      "last action prob :tensor(-4.3330)\n",
      "1 game average :38.05099914949407\n",
      "total game average :17.18434800299668\n",
      "last action prob :tensor(-3.5245)\n",
      "1 game average :38.264499144721924\n",
      "total game average :17.252129839465248\n",
      "last action prob :tensor(-4.3862)\n",
      "1 game average :38.6074991370552\n",
      "total game average :17.320576535931885\n",
      "last action prob :tensor(-3.9486)\n",
      "1 game average :38.49499913956983\n",
      "total game average :17.388226448403568\n",
      "last action prob :tensor(-3.1308)\n",
      "1 game average :38.373499142285574\n",
      "total game average :17.455058527046504\n",
      "last action prob :tensor(-5.3498)\n",
      "1 game average :38.32849914329132\n",
      "total game average :17.521323417891725\n",
      "last action prob :tensor(-2.9076)\n",
      "1 game average :38.50899913925684\n",
      "total game average :17.5877401132125\n",
      "last action prob :tensor(-2.8664)\n",
      "1 game average :38.273999144509574\n",
      "total game average :17.65299645085066\n",
      "last action prob :tensor(-5.2087)\n",
      "1 game average :37.77999915555127\n",
      "total game average :17.7162889121862\n",
      "last action prob :tensor(-4.4795)\n",
      "1 game average :38.388499141950334\n",
      "total game average :17.781092079050662\n",
      "last action prob :tensor(-2.7024)\n",
      "1 game average :38.3924991418609\n",
      "total game average :17.845502726121943\n",
      "last action prob :tensor(-2.4863)\n",
      "1 game average :38.267499144654785\n",
      "total game average :17.90912265265943\n",
      "last action prob :tensor(-3.5308)\n",
      "1 game average :37.99099915083514\n",
      "total game average :17.97148872874072\n",
      "last action prob :tensor(-2.6636)\n",
      "1 game average :38.370999142341375\n",
      "total game average :18.034645107730196\n",
      "last action prob :tensor(-3.0473)\n",
      "1 game average :38.567499137949284\n",
      "total game average :18.098018113996304\n",
      "last action prob :tensor(-2.6690)\n",
      "1 game average :38.488499139715096\n",
      "total game average :18.160758055613897\n",
      "last action prob :tensor(-3.3506)\n",
      "1 game average :38.48399913981582\n",
      "total game average :18.223099285933536\n",
      "last action prob :tensor(-5.0041)\n",
      "1 game average :38.30899914372732\n",
      "total game average :18.284524056140857\n",
      "last action prob :tensor(-2.6430)\n",
      "1 game average :38.16249914700178\n",
      "total game average :18.345127638734944\n",
      "last action prob :tensor(-4.4595)\n",
      "1 game average :38.31099914368268\n",
      "total game average :18.405814178263658\n",
      "last action prob :tensor(-2.6647)\n",
      "1 game average :37.814499154780364\n",
      "total game average :18.464628375162196\n",
      "last action prob :tensor(-3.0567)\n",
      "1 game average :38.29499914404014\n",
      "total game average :18.524538860868773\n",
      "last action prob :tensor(-2.8527)\n",
      "1 game average :38.04499914962816\n",
      "total game average :18.58333542800359\n",
      "last action prob :tensor(-3.6299)\n",
      "1 game average :38.23799914531416\n",
      "total game average :18.64235844216969\n",
      "last action prob :tensor(-2.3129)\n",
      "1 game average :38.58299913760288\n",
      "total game average :18.702060959221885\n",
      "last action prob :tensor(-4.1524)\n",
      "1 game average :38.2164991457948\n",
      "total game average :18.760313013510164\n",
      "last action prob :tensor(-3.2138)\n",
      "1 game average :38.3434991429561\n",
      "total game average :18.818596305562085\n",
      "last action prob :tensor(-3.1630)\n",
      "1 game average :38.64149913629524\n",
      "total game average :18.877417975682956\n",
      "last action prob :tensor(-2.6571)\n",
      "1 game average :38.73949913410477\n",
      "total game average :18.936181529406095\n",
      "last action prob :tensor(-4.8065)\n",
      "1 game average :38.44099914077689\n",
      "total game average :18.99371786454288\n",
      "last action prob :tensor(-3.0904)\n",
      "1 game average :38.64249913627293\n",
      "total game average :19.051508397695027\n",
      "last action prob :tensor(-5.0267)\n",
      "1 game average :38.66199913583697\n",
      "total game average :19.109017168188114\n",
      "last action prob :tensor(-2.4741)\n",
      "1 game average :38.33999914303441\n",
      "total game average :19.16524810963503\n",
      "last action prob :tensor(-2.7155)\n",
      "1 game average :38.02699915003048\n",
      "total game average :19.220238637449597\n",
      "last action prob :tensor(-3.6795)\n",
      "1 game average :38.79049913296487\n",
      "total game average :19.27712892958772\n",
      "last action prob :tensor(-3.3506)\n",
      "1 game average :38.89749913057321\n",
      "total game average :19.333999567851446\n",
      "last action prob :tensor(-2.7863)\n",
      "1 game average :38.77949913321066\n",
      "total game average :19.390200433647284\n",
      "last action prob :tensor(-3.4435)\n",
      "1 game average :38.58099913764753\n",
      "total game average :19.445505329047858\n",
      "last action prob :tensor(-3.0684)\n",
      "1 game average :38.35349914273264\n",
      "total game average :19.499838644604424\n",
      "last action prob :tensor(-4.0576)\n",
      "1 game average :38.465499140229134\n",
      "total game average :19.554181511354066\n",
      "last action prob :tensor(-4.2509)\n",
      "1 game average :38.13649914758293\n",
      "total game average :19.607273847457577\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for episode in range(num_episodes):\n",
    "    score = 0\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    s0 = env_info.vector_observations \n",
    "    traj_list.append(list())\n",
    "    traj_rewards.append(list())\n",
    "    advantage_rewards.append(list())\n",
    "    advantage_list.append(list())\n",
    "    game_score = 0\n",
    "    for frame in range(1000000):\n",
    "        if frame > -1:\n",
    "            action = Agent.get_action(s0)\n",
    "        else:\n",
    "            action = 0  \n",
    "        env_info = env.step(action.detach().numpy())[brain_name]\n",
    "        reward = np.array(env_info.rewards)\n",
    "        state = env_info.vector_observations\n",
    "        game_score += sum(reward)/20\n",
    "        if frame > -1:\n",
    "            av_rew += sum(reward)/20\n",
    "            traj_list[-1].append([s0, action, state])\n",
    "            traj_rewards[-1].append(reward)\n",
    "        s0 = state\n",
    "        #Ends when done\n",
    "        if np.any(env_info.local_done):\n",
    "            score_list.append(game_score)\n",
    "            break\n",
    "    #Get discounted rewards to train value function\n",
    "    advantage_rewards[-1] = deepcopy(traj_rewards[-1])\n",
    "    weighted_rewards = 0\n",
    "    for i in reversed(range(len(traj_rewards[-1])-1)):\n",
    "        advantage_rewards[-1][i] += advantage_rewards[-1][i+1] * discount\n",
    "    l = 0.96\n",
    "    cur_advantage = 0\n",
    "    advantage_list[-1] = deepcopy(advantage_rewards[-1])\n",
    "    #Calculates Advantage Using Generalized Advantage Estimatior\n",
    "    for i in reversed(range(len(traj_rewards[-1]))):\n",
    "        new_adv = torch.from_numpy(traj_rewards[-1][i]).float().view((20,1)) + discount * Agent.value_est(torch.from_numpy(traj_list[-1][i][2]).float()) - Agent.value_est(torch.from_numpy(traj_list[-1][i][0]).float())\n",
    "        cur_advantage = cur_advantage * l * discount + new_adv\n",
    "        advantage_list[-1][i] = cur_advantage\n",
    "    #Update Policy\n",
    "    if episode%traj_num == 0 and episode > -1:\n",
    "        advantage_mean = sum([torch.mean(i) for j in advantage_list for i in j])/len([torch.mean(i) for j in advantage_list for i in j])\n",
    "        advantage_std = sum([torch.std(i)**2 for j in advantage_list for i in j])**0.5\n",
    "        old_pi = deepcopy(Agent.pi)\n",
    "        for batch in range(batches):\n",
    "            loss = 0\n",
    "            for i in range(batch_size):\n",
    "                m = randint(0,len(traj_list)-1)\n",
    "                traj = traj_list[m]\n",
    "                n = randint(0,len(traj)-1)\n",
    "                o = randint(0,19)\n",
    "                #Calculates probability of picking action\n",
    "                dist = Agent.pi(torch.from_numpy(traj[n][0][o]).float())\n",
    "                var = Agent.var\n",
    "                dist = dist[:action_space]\n",
    "                dist = tdist.multivariate_normal.MultivariateNormal(dist, torch.eye(4) * Agent.var)\n",
    "                prob = dist.log_prob(torch.tensor(traj[n][1][o]))\n",
    "                #Calculates old probability of picking action\n",
    "                old_dist = old_pi(torch.from_numpy(traj[n][0][o]).float())\n",
    "                old_var = Agent.var\n",
    "                old_dist = old_dist[:action_space]\n",
    "                old_dist = tdist.multivariate_normal.MultivariateNormal(old_dist, torch.eye(4) * Agent.var)\n",
    "                old_prob = old_dist.log_prob(torch.tensor(traj[n][1][o]))\n",
    "                \n",
    "                ratio = torch.exp(prob-old_prob)\n",
    "                advantage = (advantage_list[m][n][o] - advantage_mean)/(advantage_std+0.0001)\n",
    "                #Clipping terms\n",
    "                if advantage[0] > 0:\n",
    "                    loss += torch.min(ratio, torch.from_numpy(np.array(1 + epsilon)).float()) * -1 * advantage\n",
    "                else:\n",
    "                    loss += torch.max(ratio, torch.from_numpy(np.array(1 - epsilon)).float()) * -1 * advantage\n",
    "            Agent.optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            Agent.optimizer.step()\n",
    "            \n",
    "        #Update value function\n",
    "        if episode > 10:\n",
    "            x = 50\n",
    "        else:\n",
    "            x = 200\n",
    "        for batch in range(x):\n",
    "            loss2 = 0\n",
    "            for i in range(200):\n",
    "                m = randint(0,len(traj_list)-1)\n",
    "                traj = traj_list[m]\n",
    "                n = randint(0,len(traj)-1)\n",
    "                o = randint(0,19)\n",
    "                loss2 += (torch.from_numpy(advantage_rewards[m][n]).float()[o] - Agent.value_est(torch.from_numpy(traj[n][0][o]).float())[0])**2\n",
    "            Agent.optimizer2.zero_grad()\n",
    "            loss2.backward(retain_graph=True)\n",
    "            Agent.optimizer2.step()\n",
    "        print('last action prob :' + str(prob))\n",
    "        print('1 game average :' + str(av_rew/traj_num))\n",
    "        rew_list.append(av_rew/traj_num)\n",
    "        print('total game average :' + str(sum(rew_list)/len(rew_list)))\n",
    "        av_rew = 0\n",
    "        traj_list = list()\n",
    "        traj_rewards = list()\n",
    "        advantage_rewards = list()\n",
    "        advantage_list = list()\n",
    "        #Anneals learning rate\n",
    "        Agent.scheduler.step()\n",
    "        Agent.scheduler2.step()\n",
    "        #Slowly anneals variance to 0.5. Too low variance resulted in loss of performance\n",
    "        if Agent.var > 0.5:\n",
    "            Agent.var *= 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves Model\n",
    "torch.save(Agent.pi.state_dict(), 'Reacher_PPO_Actor')\n",
    "torch.save(Agent.value_est.state_dict(),'Reacher_PPO_Critic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.06057432809384\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plots learning curve\n",
    "plt.plot(score_list)\n",
    "print(sum(score_list[195:295])/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run with trained model\n",
    "pi = Policy_Net()\n",
    "critic = Critic_Net()\n",
    "Agent = Actor(33, 0.99, pi,critic)\n",
    "Agent.pi.load_state_dict(torch.load('Reacher_PPO_Actor'))\n",
    "Agent.value_est.load_state_dict(torch.load('Reacher_PPO_Critic'))\n",
    "Agent.var = torch.tensor([0.001])\n",
    "env_info = env.reset(train_mode=False)[brain_name]     \n",
    "states = env_info.vector_observations                  \n",
    "scores = 0                        \n",
    "while True:\n",
    "    action = Agent.get_action(states)\n",
    "    env_info = env.step(action.detach().numpy())[brain_name]           \n",
    "    next_states = env_info.vector_observations         \n",
    "    rewards = env_info.rewards                        \n",
    "    dones = env_info.local_done                       \n",
    "    scores += sum(env_info.rewards)                        \n",
    "    states = next_states                               \n",
    "    if np.any(dones):                                  \n",
    "        break\n",
    "print('Score: ' + str(scores/20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
